{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField, \n",
    "    StringType, IntegerType, DoubleType,\n",
    "    DateType, FloatType,DataType, TimestampNTZType, TimestampType\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando conex√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "           .appName('SparkByExamples.com') \\\n",
    "           .config(\"spark.jars\", \"C:\\\\Program Files (x86)\\\\PostgreSQL\\\\pgJDBC\\\\postgresql-42.7.2.jar\")\\\n",
    "           .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://mateus-win:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>SparkByExamples.com</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1f3ff614f20>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Propriedades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"jdbc:postgresql://localhost:5432/ecommerce\"\n",
    "properties = {\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"datascience007\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lendo em spark e passando para postgres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### olistCustomers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "olistCustomers = spark.read.format(\"csv\")\\\n",
    "                    .options(header=\"true\", delimiter=',', infer='false')\\\n",
    "                .load(\"dataset_limpo_para_analise\\\\olist_customers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "olistCustomers.write\\\n",
    "    .jdbc(url=url, table=\"olist_Customers\", mode=\"overwrite\", properties=properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### olistOrderItems\n",
    "Tipando os atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"order_id\"     ,       StringType(), False),\n",
    "    StructField(\"order_item_id\",       IntegerType(), False),\n",
    "    StructField(\"product_id\"   ,       StringType(), False),\n",
    "    StructField(\"seller_id\"    ,       StringType(), False),\n",
    "    StructField(\"shipping_limit_date\", StringType(), True),\n",
    "    StructField(\"price\",               FloatType(), False),\n",
    "    StructField(\"freight_value\",       FloatType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "olistOrderItems = spark.read.format(\"csv\")\\\n",
    "                    .options(header=\"true\", delimiter=',', infer='false')\\\n",
    "                    .schema(schema)\\\n",
    "                .load(\"dataset_limpo_para_analise\\\\olist_order_items.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "olistOrderItems.write\\\n",
    "    .jdbc(url  =url, \n",
    "          table=\"olist_Order_Items\", \n",
    "          mode =\"overwrite\", \n",
    "          properties=properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### olistOrderPayments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"order_id\"     ,       StringType(), False),\n",
    "    StructField(\"payment_sequential\",  IntegerType(), False),\n",
    "    StructField(\"payment_type\"    ,    StringType(), False),\n",
    "    StructField(\"payment_installments\", IntegerType(), False),\n",
    "    StructField(\"payment_value\",       FloatType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "olistOrderPayments = spark.read.format(\"csv\")\\\n",
    "                    .options(header=\"true\", delimiter=',', infer='false')\\\n",
    "                    .schema(schema)\\\n",
    "                .load(\"dataset_limpo_para_analise\\\\olist_order_payments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "olistOrderPayments.write\\\n",
    "    .jdbc(url  =url, \n",
    "          table=\"olist_Order_Payments\", \n",
    "          mode =\"overwrite\", \n",
    "          properties=properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### olistOrderReview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"review_id\"    ,       StringType(), False),\n",
    "    StructField(\"order_id\"     ,       StringType(), False),\n",
    "    StructField(\"review_score\" ,       IntegerType(), False),\n",
    "    StructField(\"review_comment_title\" , StringType(), False),\n",
    "    StructField(\"review_comment_message\", StringType(), False),\n",
    "    StructField(\"review_creation_date\",   TimestampType(), False),\n",
    "    StructField(\"review_answer_timestamp\",TimestampType(), False)\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "olistOrderReviews = spark.read.format(\"csv\")\\\n",
    "                    .options(header=\"true\", delimiter=',', infer='false',multiline='true')\\\n",
    "                    .schema(schema)\\\n",
    "                .load(\"dataset_limpo_para_analise\\\\olist_order_review.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "olistOrderReviews.write\\\n",
    "    .jdbc(url  =url, \n",
    "          table=\"olist_Order_Reviews\", \n",
    "          mode =\"overwrite\", \n",
    "          properties=properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### olistSellers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "olistSeller = spark.read.format(\"csv\")\\\n",
    "                .options(header=\"true\", delimiter=',', infer='false')\\\n",
    "            .load(\"dataset_limpo_para_analise\\\\olist_sellers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "olistSeller.write\\\n",
    "    .jdbc(url  =url, \n",
    "          table=\"olist_Seller\", \n",
    "          mode =\"overwrite\", \n",
    "          properties=properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### olistProducts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "olistProducts = spark.read.format(\"csv\")\\\n",
    "                    .options(header=\"true\", delimiter=',', infer='false')\\\n",
    "                .load(\"dataset_limpo_para_analise\\\\olist_products.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, product_id: string, product_category_name: string, product_name_lenght: string, product_description_lenght: string, product_photos_qty: string, product_weight_g: string, product_length_cm: string, product_height_cm: string, product_width_cm: string]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olistProducts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### olistGeolocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"geolocation_zip_code_prefix\"    , StringType(), False),\n",
    "    StructField(\"geolocation_lat\"                , DoubleType(), False),\n",
    "    StructField(\"geolocation_lng\"                , DoubleType(), False),\n",
    "    StructField(\"geolocation_city\"               , StringType(), False),\n",
    "    StructField(\"geolocation_state\"             , StringType(), False),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "olistGeolocation = spark.read.format(\"csv\")\\\n",
    "                    .options(header=\"true\", delimiter=',', infer='false')\\\n",
    "                    .schema(schema)\\\n",
    "                .load(\"dataset\\\\olist_geolocation_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+-------------------+------------------+----------------+-----------------+\n",
      "|geolocation_zip_code_prefix|    geolocation_lat|   geolocation_lng|geolocation_city|geolocation_state|\n",
      "+---------------------------+-------------------+------------------+----------------+-----------------+\n",
      "|                      01037| -23.54562128115268|-46.63929204800168|       sao paulo|               SP|\n",
      "|                      01046|-23.546081127035535|-46.64482029837157|       sao paulo|               SP|\n",
      "+---------------------------+-------------------+------------------+----------------+-----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "olistGeolocation.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "olistGeolocation.write\\\n",
    "    .jdbc(url  =url, \n",
    "          table=\"olist_Geolocation\", \n",
    "          mode =\"overwrite\", \n",
    "          properties=properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### olistOrder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('order_id', StringType(), False), StructField('customer_id', StringType(), False), StructField('order_status', StringType(), False), StructField('order_purchase_timestamp', TimestampType(), False), StructField('order_approved_at', TimestampType(), True), StructField('order_delivered_carrier_date', TimestampType(), True), StructField('order_delivered_customer_date', TimestampType(), True), StructField('order_estimated_delivery_date', TimestampType(), False), StructField('status_', StringType(), False)])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"order_id\"    ,       StringType(), False),\n",
    "    StructField(\"customer_id\" ,       StringType(), False),\n",
    "    StructField(\"order_status\" ,      StringType(), False),\n",
    "    StructField(\"order_purchase_timestamp\",    TimestampType(), False),\n",
    "    StructField(\"order_approved_at\" ,          TimestampType(), True),\n",
    "    StructField(\"order_delivered_carrier_date\",TimestampType(), True),\n",
    "    StructField(\"order_delivered_customer_date\",TimestampType(), True),\n",
    "    StructField(\"order_estimated_delivery_date\",TimestampType(), False),\n",
    "    StructField(\"status_\",StringType(), False)\n",
    "\n",
    "])\n",
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "olistOrder = spark.read.format('csv')\\\n",
    "                    .options(header=\"true\", delimiter=',', infer='false')\\\n",
    "                    .schema(schema)\\\n",
    "                .load(\"dataset_limpo_para_analise\\\\olist_order.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "olistOrder.write\\\n",
    "    .jdbc(url  =url, \n",
    "          table=\"olist_order\", \n",
    "          mode =\"overwrite\", \n",
    "          properties=properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+------------------------+-------------------+----------------------------+-----------------------------+-----------------------------+-------+\n",
      "|            order_id|         customer_id|order_status|order_purchase_timestamp|  order_approved_at|order_delivered_carrier_date|order_delivered_customer_date|order_estimated_delivery_date|status_|\n",
      "+--------------------+--------------------+------------+------------------------+-------------------+----------------------------+-----------------------------+-----------------------------+-------+\n",
      "|e481f51cbdc54678b...|9ef432eb625129730...|    entregue|     2017-10-02 10:56:33|2017-10-02 11:07:15|         2017-10-04 19:55:00|          2017-10-10 21:25:13|          2017-10-18 00:00:00|     ok|\n",
      "|53cdb2fc8bc7dce0b...|b0830fb4747a6c6d2...|    entregue|     2018-07-24 20:41:37|2018-07-26 03:24:27|         2018-07-26 14:31:00|          2018-08-07 15:27:45|          2018-08-13 00:00:00|     ok|\n",
      "+--------------------+--------------------+------------+------------------------+-------------------+----------------------------+-----------------------------+-----------------------------+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "olistOrder.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
